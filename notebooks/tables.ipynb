{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Tables Generator\n",
    "Reads `full_HDBSCAN_metadata.csv` (train/test) and `best_per_model_HDBSCAN.csv` to produce LaTeX tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_FULL  = \"../compare_flu/results/full_HDBSCAN_metadata.csv\"\n",
    "TEST_FULL   = \"../compare_flu2018-2020/results/full_HDBSCAN_metadata.csv\"\n",
    "BEST_MODEL  = \"../compare_flu2018-2020/results/best_per_model_HDBSCAN.csv\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_FULL)\n",
    "test  = pd.read_csv(TEST_FULL)\n",
    "best  = pd.read_csv(BEST_MODEL)\n",
    "\n",
    "print(\"train:\", train.shape, \"  test:\", test.shape, \"  best:\", best.shape)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\nMODEL_DISPLAY = {\n    \"t33-650M\": \"ESM-2(650M)\",\n    \"t36-3B\":   \"ESM-2(3B)\",\n    \"t48-15B\":  \"ESM-2(15B)\",\n    \"protbert\": \"ProtBert\",\n    \"prot5\":    \"ProtT5\",\n    \"CARP\":     \"CARP\",\n}\nPOOL_DISPLAY = {\n    \"mean\":          \"mean\",\n    \"bos\":           \"BOS\",\n    \"attentionmean\": \"attn-mean\",\n    \"sitemean\":      \"site-mean\",\n}\nDIM_DISPLAY = {\n    \"t-sne\": \"t-SNE\",\n    \"umap\":  \"UMAP\",\n    \"pca\":   \"PCA\",\n    \"mds\":   \"MDS\",\n}\n\ndef extract_epsilon(predicted_clusters_column):\n    m = re.search(r'_cluster_at_([\\d.]+)$', str(predicted_clusters_column))\n    return float(m.group(1)) if m else None\n\ndef parse_method(method):\n    empty = dict(dim=None, metric=None, components=None, base_model=None, pooling=None)\n    if not method.startswith(\"reduced_\"):\n        return empty\n    s = method[:-4] if method.endswith(\"_All\") else method\n    parts = s.split(\"_\")\n    if len(parts) < 5:\n        return empty\n    dim, metric = parts[1], parts[2]\n    try:\n        components = int(parts[3])\n    except ValueError:\n        return empty\n    model_full = \"_\".join(parts[4:])\n    tokens = model_full.split(\"-\")\n    if tokens[-1] in POOL_DISPLAY:\n        pooling    = tokens[-1]\n        base_model = \"-\".join(tokens[:-1])\n    else:\n        pooling    = None\n        base_model = model_full\n    return dict(dim=dim, metric=metric, components=components,\n                base_model=base_model, pooling=pooling)\n\nfor m in [\"reduced_t-sne_cosine_1_t33-650M-mean_All\",\n          \"reduced_t-sne_euclidean_2_CARP\",\n          \"reduced_t-sne_euclidean_2_t48-15B-attentionmean_All\",\n          \"t-sne\", \"genetic\"]:\n    print(m, \"->\", parse_method(m))\n\ntrain[\"epsilon\"] = train[\"predicted_clusters_column\"].apply(extract_epsilon)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 1 – Baseline scores (genetic dim-reduction methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_METHODS = [\"t-sne\", \"umap\", \"pca\", \"mds\"]\n",
    "\n",
    "train_base = (\n",
    "    train[train[\"method\"].isin(BASELINE_METHODS)]\n",
    "    .sort_values(\"normalized_vi\")\n",
    "    .groupby(\"method\", sort=False)\n",
    "    .first()\n",
    "    .reset_index()[[\"method\", \"epsilon\", \"normalized_vi\",\n",
    "                    \"adjusted_rand_score\", \"normalized_mutual_info_score\"]]\n",
    "    .rename(columns={\n",
    "        \"normalized_vi\":              \"train_nvi\",\n",
    "        \"adjusted_rand_score\":        \"train_ari\",\n",
    "        \"normalized_mutual_info_score\": \"train_nmi\",\n",
    "    })\n",
    ")\n",
    "\n",
    "test_base = (\n",
    "    test[test[\"method\"].isin(BASELINE_METHODS)]\n",
    "    [[\"method\", \"normalized_vi\", \"adjusted_rand_score\", \"normalized_mutual_info_score\"]]\n",
    "    .rename(columns={\n",
    "        \"normalized_vi\":              \"test_nvi\",\n",
    "        \"adjusted_rand_score\":        \"test_ari\",\n",
    "        \"normalized_mutual_info_score\": \"test_nmi\",\n",
    "    })\n",
    ")\n",
    "\n",
    "baseline = train_base.merge(test_base, on=\"method\")\n",
    "# enforce display order\n",
    "order = {m: i for i, m in enumerate(BASELINE_METHODS)}\n",
    "baseline[\"_ord\"] = baseline[\"method\"].map(order)\n",
    "baseline = baseline.sort_values(\"_ord\").drop(columns=\"_ord\")\n",
    "baseline[\"method\"] = baseline[\"method\"].map(lambda m: DIM_DISPLAY.get(m, m))\n",
    "\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_baseline(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rows.append(\n",
    "            f\"{r['method']:<8} & {r['epsilon']:<5} \"\n",
    "            f\"& {r['train_nvi']:.4f} & {r['test_nvi']:.4f} \"\n",
    "            f\"& {r['train_nmi']:.4f} & {r['test_nmi']:.4f} \"\n",
    "            f\"& {r['train_ari']:.4f} & {r['test_ari']:.4f} \\\\\\\\\"\n",
    "        )\n",
    "    header = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\caption{Baseline scores. Lower NVI is better, higher NMI and ARI are better.}\n",
    "\\label{tab:baseline-results}\n",
    "\\begin{tabular}{|l|l|l|l|l|l|l|l|}\n",
    "\\hline\n",
    "Method & HDBSCAN~$\\epsilon$ & Train NVI & Test NVI & Train NMI & Test NMI & Train ARI & Test ARI\\\\\\\\\n",
    "\\hline\"\"\"\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\"\"\"\n",
    "    print(header)\n",
    "    print(\"\\n\".join(rows))\n",
    "    print(footer)\n",
    "\n",
    "latex_baseline(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2 – Top 10 training PLM results (mean pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plm_mask = train[\"method\"].str.startswith(\"reduced_\") & ~train[\"method\"].isin(BASELINE_METHODS)\n",
    "plm_train = train[plm_mask].copy()\n",
    "\n",
    "parsed = plm_train[\"method\"].apply(parse_method)\n",
    "plm_train = plm_train.join(pd.DataFrame(parsed.tolist(), index=plm_train.index))\n",
    "plm_train = plm_train[plm_train[\"pooling\"].isin([\"mean\"]) | plm_train[\"pooling\"].isna()]\n",
    "\n",
    "top10 = (\n",
    "    plm_train.sort_values(\"normalized_vi\")\n",
    "    .head(10)\n",
    "    [[\"base_model\", \"dim\", \"metric\", \"components\", \"epsilon\",\n",
    "      \"normalized_vi\", \"adjusted_rand_score\", \"normalized_mutual_info_score\"]]\n",
    "    .copy()\n",
    ")\n",
    "top10[\"base_model\"] = top10[\"base_model\"].map(model_label)\n",
    "top10[\"dim\"]        = top10[\"dim\"].map(lambda d: DIM_DISPLAY.get(d, d))\n",
    "top10[\"metric\"]     = top10[\"metric\"].str.capitalize()\n",
    "top10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_top10(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        rows.append(\n",
    "            f\"{r['base_model']:<14} & {r['dim']:<6} & {r['metric']:<10} \"\n",
    "            f\"& {int(r['components'])} & {r['epsilon']:<5} \"\n",
    "            f\"& {r['normalized_vi']:.4f} \"\n",
    "            f\"& {r['normalized_mutual_info_score']:.4f} \"\n",
    "            f\"& {r['adjusted_rand_score']:.4f} \\\\\\\\\"\n",
    "        )\n",
    "    header = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\caption{Top 10 training results using protein language model embeddings and mean-pooling.\n",
    "Lower NVI is better, higher NMI and ARI are better.}\n",
    "\\label{tab:top10-results}\n",
    "\\begin{tabular}{|l|l|l|c|c|c|c|c|}\n",
    "\\hline\n",
    "Model & Dim.~red. & Metric & Dims & HDBSCAN~$\\epsilon$ & NVI & NMI & ARI\\\\\\\\\n",
    "\\hline\"\"\"\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\"\"\"\n",
    "    print(header)\n",
    "    print(\"\\n\".join(rows))\n",
    "    print(footer)\n",
    "\n",
    "latex_top10(top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3 – Best configuration per model (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_opt = (\n",
    "    train.sort_values(\"normalized_vi\")\n",
    "    .groupby(\"method\", sort=False)\n",
    "    .first()\n",
    "    .reset_index()[[\"method\", \"epsilon\"]]\n",
    ")\n",
    "\n",
    "best_with_eps = best.merge(train_opt, on=\"method\", how=\"left\")\n",
    "\n",
    "parsed_df = pd.DataFrame(best_with_eps[\"method\"].apply(parse_method).tolist(), index=best_with_eps.index)\n",
    "for col in [\"dim\", \"metric\", \"components\", \"base_model\", \"pooling\", \"gene\"]:\n",
    "    best_with_eps[col] = parsed_df.get(col)\n",
    "\n",
    "best_with_eps = best_with_eps[~best_with_eps[\"method\"].str.contains(\"sitemean|attentionmean|bos\")]\n",
    "\n",
    "def fill_display(row):\n",
    "    if pd.isna(row.get(\"dim\")):\n",
    "        return DIM_DISPLAY.get(row[\"method\"], row[\"method\"])\n",
    "    return DIM_DISPLAY.get(row[\"dim\"], row[\"dim\"])\n",
    "\n",
    "best_with_eps[\"dim_label\"]    = best_with_eps.apply(fill_display, axis=1)\n",
    "best_with_eps[\"model_label\"]  = best_with_eps[\"model\"].map(lambda m: MODEL_DISPLAY.get(m, m))\n",
    "best_with_eps[\"metric_label\"] = best_with_eps[\"metric\"].fillna(\"\").str.capitalize()\n",
    "\n",
    "cols = [\"model_label\", \"dim_label\", \"metric_label\", \"components\", \"epsilon\",\n",
    "        \"train_normalized_vi\", \"test_normalized_vi\",\n",
    "        \"train_normalized_mutual_info_score\", \"test_normalized_mutual_info_score\",\n",
    "        \"train_adjusted_rand_score\", \"test_adjusted_rand_score\"]\n",
    "best_with_eps[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_best_per_model(df):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        comp = int(r['components']) if pd.notna(r.get('components')) else \"--\"\n",
    "        met  = r['metric_label'] if r['metric_label'] else \"--\"\n",
    "        rows.append(\n",
    "            f\"{r['model_label']:<14} & {r['dim_label']:<7} & {met:<10} \"\n",
    "            f\"& {comp} & {r['epsilon']:<5} \"\n",
    "            f\"& {r['train_normalized_vi']:.4f} & {r['test_normalized_vi']:.4f} \"\n",
    "            f\"& {r['train_normalized_mutual_info_score']:.4f} & {r['test_normalized_mutual_info_score']:.4f} \"\n",
    "            f\"& {r['train_adjusted_rand_score']:.4f} & {r['test_adjusted_rand_score']:.4f} \\\\\\\\\"\n",
    "        )\n",
    "    header = r\"\"\"\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\caption{Best configuration for each model type.\n",
    "Lower NVI is better, higher NMI and ARI are better.}\n",
    "\\label{tab:best-config}\n",
    "\\begin{tabular}{|l|l|l|c|c|c|c|c|c|c|c|}\n",
    "\\hline\n",
    "Model & Dim.~red. & Metric & Dims & $\\epsilon$ & Train NVI & Test NVI & Train NMI & Test NMI & Train ARI & Test ARI\\\\\\\\\n",
    "\\hline\"\"\"\n",
    "    footer = r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\"\"\"\n",
    "    print(header)\n",
    "    print(\"\\n\".join(rows))\n",
    "    print(footer)\n",
    "\n",
    "latex_best_per_model(best_with_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4 – Pooling method comparison (test NVI/NMI/ARI per model × pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\nbest_all = best.copy()\nparsed_df = pd.DataFrame(best_all[\"method\"].apply(parse_method).tolist(), index=best_all.index)\nfor col in [\"dim\", \"metric\", \"components\", \"base_model\", \"pooling\"]:\n    best_all[col] = parsed_df.get(col)\nbest_all[\"base_model_label\"] = best_all[\"base_model\"].map(lambda m: MODEL_DISPLAY.get(m, m))\n\npool_rows = best_all[best_all[\"pooling\"].notna()].copy()\npool_rows[\"pooling_label\"] = pool_rows[\"pooling\"].map(POOL_DISPLAY)\n\npivot_nvi = pool_rows.pivot_table(\n    index=\"base_model_label\", columns=\"pooling_label\",\n    values=\"test_normalized_vi\", aggfunc=\"min\"\n).round(4)\npivot_nmi = pool_rows.pivot_table(\n    index=\"base_model_label\", columns=\"pooling_label\",\n    values=\"test_normalized_mutual_info_score\", aggfunc=\"max\"\n).round(4)\npivot_ari = pool_rows.pivot_table(\n    index=\"base_model_label\", columns=\"pooling_label\",\n    values=\"test_adjusted_rand_score\", aggfunc=\"max\"\n).round(4)\n\nprint(\"NVI by pooling:\")\ndisplay(pivot_nvi)\nprint(\"\\nNMI by pooling:\")\ndisplay(pivot_nmi)\nprint(\"\\nARI by pooling:\")\ndisplay(pivot_ari)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_pooling_table(pool_rows, metric_col, caption, label):\n",
    "    POOL_ORDER = [\"mean\", \"BOS\", \"attn-mean\", \"site-mean\"]\n",
    "    present = [p for p in POOL_ORDER if p in pool_rows[\"pooling_label\"].values]\n",
    "\n",
    "    header = (\n",
    "        f\"\\\\begin{{table}}[h]\\n\\\\centering\\n\"\n",
    "        f\"\\\\caption{{{caption}}}\\n\\\\label{{{label}}}\\n\"\n",
    "        f\"\\\\begin{{tabular}}{{|l|{'c|' * len(present)}}}\\n\\\\hline\\n\"\n",
    "        f\"Model & {' & '.join(present)} \\\\\\\\\\n\\\\hline\"\n",
    "    )\n",
    "    rows = []\n",
    "    for model, grp in pool_rows.groupby(\"model_label\"):\n",
    "        vals = {r[\"pooling_label\"]: r[metric_col] for _, r in grp.iterrows()}\n",
    "        cells = \" & \".join(f\"{vals.get(p, float('nan')):.4f}\" if p in vals else \"--\" for p in present)\n",
    "        rows.append(f\"{model} & {cells} \\\\\\\\\")\n",
    "    footer = \"\\\\hline\\n\\\\end{tabular}\\n\\\\end{table}\"\n",
    "    print(header)\n",
    "    print(\"\\n\".join(rows))\n",
    "    print(footer)\n",
    "\n",
    "latex_pooling_table(\n",
    "    pool_rows, \"test_normalized_vi\",\n",
    "    \"Test NVI by model and pooling strategy. Lower is better.\",\n",
    "    \"tab:pooling-nvi\"\n",
    ")\n",
    "print()\n",
    "latex_pooling_table(\n",
    "    pool_rows, \"test_normalized_mutual_info_score\",\n",
    "    \"Test NMI by model and pooling strategy. Higher is better.\",\n",
    "    \"tab:pooling-nmi\"\n",
    ")\n",
    "print()\n",
    "latex_pooling_table(\n",
    "    pool_rows, \"test_adjusted_rand_score\",\n",
    "    \"Test ARI by model and pooling strategy. Higher is better.\",\n",
    "    \"tab:pooling-ari\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}